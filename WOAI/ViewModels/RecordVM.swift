import Foundation
import Combine
import AVFAudio

class RecordVM: ObservableObject {
    @Published var labelText: String = ""
    @Published var isRecording: Bool = false

    private var audioRecorder: AVAudioRecorder?
    private let audioSession = AVAudioSession.sharedInstance()
    private var recordingFileURL: URL?
    private var fileName: String = ""

    private let openAIManager: OpenAiManager
    private let whisperManager: WhisperManager

    init() {
        guard let apiKey = Bundle.main.object(forInfoDictionaryKey: "chatGPTApiKey") as? String else {
            fatalError("API_KEY not found in Info.plist")
        }

        self.openAIManager = OpenAiManager(apiKey: apiKey)
        self.whisperManager = WhisperManager(chatGPT: self.openAIManager)

        Task {
            await requestPermissionsAndConfigureSession()
        }
    }

    func toggleRecording() {
        if isRecording {
            stopRecording()
        } else {
            startRecording()
        }
    }

    private func startRecording() {
        isRecording = true
        labelText = "\në…¹ìŒì¤‘..."

        fileName = "recording_\(UUID().uuidString).m4a"
        let fileURL = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!.appendingPathComponent(fileName)
        recordingFileURL = fileURL

        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 44100,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            audioRecorder = try AVAudioRecorder(url: fileURL, settings: settings)
            audioRecorder?.record()
        } catch {
            print("ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: \(error)")
        }
    }

    private func stopRecording() {
        isRecording = false
        labelText = "\në¶„ì„ì¤‘..."
        audioRecorder?.stop()

        if let url = recordingFileURL {
            transcribeAndSummarize(url: url)
        }
    }

    private func transcribeAndSummarize(url: URL) {
        Task {
            do {
                let text = try await whisperManager.transcribeAudio(at: url)
                let stream = try await openAIManager.sendMessageStream(text: text)
                
                var result = ""
                for try await message in stream {
                    result += message
                    await MainActor.run {
                        self.labelText = result
                    }
                }
            } catch {
                print("âŒ ì˜¤ë¥˜ ë°œìƒ: \(error)")
                await MainActor.run {
                    self.labelText = "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!"
                }
            }
        }
    }

    private func requestPermissionsAndConfigureSession() async {
        do {
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
            try audioSession.setActive(true)

            let granted = await withCheckedContinuation { continuation in
                AVAudioApplication.requestRecordPermission { allowed in
                    continuation.resume(returning: allowed)
                }
            }

            if granted {
                print("ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨")
            } else {
                print("ğŸš« ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨")
            }

        } catch {
            print("ğŸ§ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ì‹¤íŒ¨: \(error)")
        }
    }
}
